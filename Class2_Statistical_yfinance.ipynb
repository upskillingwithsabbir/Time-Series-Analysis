{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e60c717",
   "metadata": {},
   "source": [
    "# Class 2: Time Series Analysis with Statistical Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e465f822",
   "metadata": {},
   "source": [
    "This notebook delves into statistical models commonly used for time series analysis and forecasting. We will cover AR, MA, ARMA, ARIMA, SARIMAX, and GARCH models, along with model selection criteria and diagnostic checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56e33eb",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5eeef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import pmdarima as pm\n",
    "from arch import arch_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "plt.rcParams['axes.grid'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b7b3d",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed68ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download 10 years of Apple stock data\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2025-01-01'\n",
    "ticker = 'AAPL'\n",
    "\n",
    "# Fetch data using yfinance\n",
    "df = yf.download(ticker, start=start_date, end=end_date)\n",
    "print(f\"Downloaded {ticker} stock data from {start_date} to {end_date}\")\n",
    "print(f\"Shape of data: {df.shape}\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nFirst 5 rows of the data:\")\n",
    "display(df.head())\n",
    "\n",
    "# We'll focus on the 'Adj Close' price for our analysis\n",
    "ts = df['Adj Close']\n",
    "print(f\"\\nFocusing on Adjusted Close price for {ticker}\")\n",
    "\n",
    "# Create log returns for GARCH modeling\n",
    "log_returns = np.log(ts / ts.shift(1)).dropna()\n",
    "print(\"\\nCreated log returns series for GARCH modeling\")\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "train_size = int(len(ts) * 0.8)\n",
    "train_ts = ts[:train_size]\n",
    "test_ts = ts[train_size:]\n",
    "print(f\"\\nSplit data into training ({len(train_ts)} samples) and testing ({len(test_ts)} samples) sets\")\n",
    "\n",
    "# Also split the log returns\n",
    "train_returns = log_returns[:train_size]\n",
    "test_returns = log_returns[train_size:]\n",
    "\n",
    "# Plot the training and testing data\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train_ts, label='Training Data')\n",
    "plt.plot(test_ts, label='Testing Data')\n",
    "plt.title(f'{ticker} Stock Price - Train/Test Split')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94069404",
   "metadata": {},
   "source": [
    "## 2. AR, MA, ARMA, and ARIMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ba0c6",
   "metadata": {},
   "source": [
    "AR (Autoregressive) Model concept not found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a752e56",
   "metadata": {},
   "source": [
    "MA (Moving Average) Model concept not found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac3b5e",
   "metadata": {},
   "source": [
    "ARIMA Model concept not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit ARIMA(1,1,1) model on the training data\n",
    "arima_model = ARIMA(train_ts, order=(1, 1, 1))\n",
    "arima_results = arima_model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(\"ARIMA(1,1,1) Model Summary:\")\n",
    "print(arima_results.summary())\n",
    "\n",
    "# Forecast on the test set\n",
    "arima_forecast = arima_results.forecast(steps=len(test_ts))\n",
    "\n",
    "# Calculate error metrics\n",
    "arima_rmse = math.sqrt(mean_squared_error(test_ts, arima_forecast))\n",
    "arima_mae = mean_absolute_error(test_ts, arima_forecast)\n",
    "print(f\"ARIMA RMSE: {arima_rmse:.4f}\")\n",
    "print(f\"ARIMA MAE: {arima_mae:.4f}\")\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train_ts, label='Training Data')\n",
    "plt.plot(test_ts, label='Actual Test Data')\n",
    "plt.plot(test_ts.index, arima_forecast, label='ARIMA Forecast', color='red')\n",
    "plt.title('ARIMA(1,1,1) Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_09_arima_forecast.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95935f",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "\n",
    "The ARIMA(1,1,1) model combines:\n",
    "- AR(1): Autoregressive component with lag 1\n",
    "- I(1): First-order differencing to make the series stationary\n",
    "- MA(1): Moving average component with lag 1\n",
    "\n",
    "The model summary shows:\n",
    "- Coefficients for AR and MA terms\n",
    "- Statistical significance of each parameter\n",
    "- AIC, BIC, and other model fit statistics\n",
    "\n",
    "The forecast performance metrics (RMSE and MAE) provide a baseline for comparison with other models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb57782",
   "metadata": {},
   "source": [
    "## 3. AUTO ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd212907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit Auto ARIMA model\n",
    "auto_arima_model = pm.auto_arima(\n",
    "    train_ts,\n",
    "    start_p=0, start_q=0,\n",
    "    max_p=5, max_q=5, max_d=2,\n",
    "    seasonal=False,\n",
    "    trace=True,\n",
    "    error_action='ignore',\n",
    "    suppress_warnings=True,\n",
    "    stepwise=True\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(\"\\nAuto ARIMA Model Summary:\")\n",
    "print(auto_arima_model.summary())\n",
    "\n",
    "# Get the order of the best model\n",
    "best_order = auto_arima_model.order\n",
    "print(f\"\\nBest ARIMA order: {best_order}\")\n",
    "\n",
    "# Forecast on the test set\n",
    "auto_arima_forecast = auto_arima_model.predict(n_periods=len(test_ts))\n",
    "\n",
    "# Calculate error metrics\n",
    "auto_arima_rmse = math.sqrt(mean_squared_error(test_ts, auto_arima_forecast))\n",
    "auto_arima_mae = mean_absolute_error(test_ts, auto_arima_forecast)\n",
    "print(f\"Auto ARIMA RMSE: {auto_arima_rmse:.4f}\")\n",
    "print(f\"Auto ARIMA MAE: {auto_arima_mae:.4f}\")\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train_ts, label='Training Data')\n",
    "plt.plot(test_ts, label='Actual Test Data')\n",
    "plt.plot(test_ts.index, auto_arima_forecast, label='Auto ARIMA Forecast', color='green')\n",
    "plt.title(f'Auto ARIMA{best_order} Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_10_auto_arima_forecast.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c747b",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "\n",
    "Auto ARIMA automatically searches for the optimal ARIMA model parameters (p, d, q) by:\n",
    "1. Testing different combinations of parameters\n",
    "2. Evaluating models using information criteria (AIC/BIC)\n",
    "3. Selecting the model with the lowest information criterion\n",
    "\n",
    "The best model order is determined based on this search process, which saves time compared to manual testing of multiple models.\n",
    "\n",
    "Note: Auto ARIMA may sometimes select a different model than what domain knowledge would suggest, so it's important to evaluate the results critically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec7d46",
   "metadata": {},
   "source": [
    "## 4. ARIMAX and SARIMAX Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3248bb7d",
   "metadata": {},
   "source": [
    "ARIMAX Model concept not found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97656606",
   "metadata": {},
   "source": [
    "SARIMAX Model concept not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7754dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an exogenous variable (e.g., trading volume)\n",
    "# For demonstration, we'll use the trading volume as an exogenous variable\n",
    "exog_train = np.log(df['Volume'][:train_size]).values.reshape(-1, 1)\n",
    "exog_test = np.log(df['Volume'][train_size:]).values.reshape(-1, 1)\n",
    "\n",
    "# Fit SARIMAX model with exogenous variable\n",
    "# Using SARIMAX(1,1,1)(0,0,0,0) which is equivalent to ARIMAX(1,1,1)\n",
    "sarimax_model = SARIMAX(\n",
    "    train_ts,\n",
    "    exog=exog_train,\n",
    "    order=(1, 1, 1),\n",
    "    seasonal_order=(0, 0, 0, 0)  # No seasonality\n",
    ")\n",
    "sarimax_results = sarimax_model.fit(disp=False)\n",
    "\n",
    "# Print model summary\n",
    "print(\"SARIMAX(1,1,1) Model Summary:\")\n",
    "print(sarimax_results.summary())\n",
    "\n",
    "# Forecast on the test set\n",
    "sarimax_forecast = sarimax_results.forecast(steps=len(test_ts), exog=exog_test)\n",
    "\n",
    "# Calculate error metrics\n",
    "sarimax_rmse = math.sqrt(mean_squared_error(test_ts, sarimax_forecast))\n",
    "sarimax_mae = mean_absolute_error(test_ts, sarimax_forecast)\n",
    "print(f\"SARIMAX RMSE: {sarimax_rmse:.4f}\")\n",
    "print(f\"SARIMAX MAE: {sarimax_mae:.4f}\")\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train_ts, label='Training Data')\n",
    "plt.plot(test_ts, label='Actual Test Data')\n",
    "plt.plot(test_ts.index, sarimax_forecast, label='SARIMAX Forecast', color='purple')\n",
    "plt.title('SARIMAX(1,1,1) Forecast with Volume as Exogenous Variable')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_11_sarimax_forecast.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c305c7d",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "\n",
    "The SARIMAX model extends ARIMA by incorporating:\n",
    "1. Exogenous variables (X): External factors that may influence the time series (in this case, trading volume)\n",
    "2. Seasonal components (S): Patterns that repeat at regular intervals\n",
    "\n",
    "In this example:\n",
    "- We used log-transformed trading volume as an exogenous variable\n",
    "- We didn't include seasonality (seasonal_order=(0,0,0,0)) as stock prices typically don't have fixed seasonality\n",
    "\n",
    "The model summary shows:\n",
    "- Coefficients for AR, MA, and exogenous terms\n",
    "- Statistical significance of each parameter\n",
    "- AIC, BIC, and other model fit statistics\n",
    "\n",
    "Including the trading volume as an exogenous variable can potentially improve the forecast if volume has predictive power for price movements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597d734",
   "metadata": {},
   "source": [
    "## 5. ARCH and GARCH Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01589c8",
   "metadata": {},
   "source": [
    "ARCH/GARCH Model concept not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit GARCH(1,1) model on the training log returns\n",
    "garch_model = arch_model(train_returns, vol='Garch', p=1, q=1)\n",
    "garch_results = garch_model.fit(disp='off')\n",
    "\n",
    "# Print model summary\n",
    "print(\"GARCH(1,1) Model Summary:\")\n",
    "print(garch_results.summary())\n",
    "\n",
    "# Forecast volatility\n",
    "garch_forecast = garch_results.forecast(horizon=len(test_returns))\n",
    "forecast_vol = np.sqrt(garch_forecast.variance.values[-1, :])\n",
    "\n",
    "# Plot the volatility forecast\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train_returns.index[-252:], train_returns[-252:], label='Training Returns', alpha=0.5)\n",
    "plt.plot(test_returns.index, test_returns, label='Test Returns', alpha=0.5)\n",
    "plt.plot(test_returns.index, forecast_vol, label='GARCH Volatility Forecast', color='red')\n",
    "plt.title('GARCH(1,1) Volatility Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log Returns / Volatility')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_12_garch_volatility.png')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the 95% confidence intervals for returns\n",
    "conf_intervals = pd.DataFrame(index=test_returns.index)\n",
    "conf_intervals['upper'] = 1.96 * forecast_vol\n",
    "conf_intervals['lower'] = -1.96 * forecast_vol\n",
    "\n",
    "# Plot returns with confidence intervals\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_returns, label='Actual Returns', alpha=0.5)\n",
    "plt.fill_between(test_returns.index, \n",
    "                 conf_intervals['lower'], \n",
    "                 conf_intervals['upper'], \n",
    "                 color='red', alpha=0.2, \n",
    "                 label='95% Confidence Interval')\n",
    "plt.title('Returns with GARCH 95% Confidence Intervals')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log Returns')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4cd459",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "\n",
    "GARCH models are specifically designed to model volatility clustering in financial time series:\n",
    "\n",
    "1. Unlike ARIMA models that forecast the mean (price levels), GARCH models forecast variance (volatility)\n",
    "2. GARCH(1,1) means the model uses 1 lag of squared returns and 1 lag of past variance\n",
    "3. The model captures how volatility tends to cluster (periods of high volatility tend to be followed by high volatility)\n",
    "\n",
    "The model summary shows:\n",
    "- Coefficients for the constant term (omega), ARCH term (alpha), and GARCH term (beta)\n",
    "- Statistical significance of each parameter\n",
    "- Information criteria and other model fit statistics\n",
    "\n",
    "Applications of GARCH models:\n",
    "- Risk management and VaR (Value at Risk) calculations\n",
    "- Option pricing\n",
    "- Portfolio optimization\n",
    "- Trading strategies based on volatility forecasts\n",
    "\n",
    "The 95% confidence intervals show the expected range of returns based on the forecasted volatility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2e1c6",
   "metadata": {},
   "source": [
    "## 6. Diagnostic Checks and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5f1c8",
   "metadata": {},
   "source": [
    "Diagnostic Check concept not found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbabc08",
   "metadata": {},
   "source": [
    "AIC/BIC concept not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b438c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's perform diagnostic checks on the Auto ARIMA model residuals\n",
    "residuals = auto_arima_model.resid()\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(211)\n",
    "plt.plot(residuals)\n",
    "plt.title('Residuals of Auto ARIMA Model')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Residual')\n",
    "plt.subplot(212)\n",
    "plt.hist(residuals, bins=30)\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_13_auto_arima_residuals.png')\n",
    "plt.show()\n",
    "\n",
    "# Check for autocorrelation in residuals\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(211)\n",
    "plot_acf(residuals, lags=40, alpha=0.05, title='ACF of Residuals')\n",
    "plt.subplot(212)\n",
    "plot_pacf(residuals, lags=40, alpha=0.05, title='PACF of Residuals')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_14_residual_acf_pacf.png')\n",
    "plt.show()\n",
    "\n",
    "# Ljung-Box test for autocorrelation\n",
    "lb_test = acorr_ljungbox(residuals, lags=[10, 20, 30], return_df=True)\n",
    "print(\"Ljung-Box Test for Autocorrelation in Residuals:\")\n",
    "print(lb_test)\n",
    "\n",
    "# Compare information criteria for model selection\n",
    "print(\"\\nInformation Criteria for Model Selection:\")\n",
    "print(f\"ARIMA(1,1,1) - AIC: {arima_results.aic:.2f}, BIC: {arima_results.bic:.2f}\")\n",
    "print(f\"Auto ARIMA{best_order} - AIC: {auto_arima_model.aic():.2f}, BIC: {auto_arima_model.bic():.2f}\")\n",
    "print(f\"SARIMAX(1,1,1) - AIC: {sarimax_results.aic:.2f}, BIC: {sarimax_results.bic:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f1a6d",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "\n",
    "Diagnostic checks are crucial to validate model assumptions and ensure the model is appropriate:\n",
    "\n",
    "1. Residual Analysis:\n",
    "   - Residuals should be random with no pattern (white noise)\n",
    "   - The histogram should approximate a normal distribution\n",
    "   - No significant autocorrelation should be present in residuals\n",
    "\n",
    "2. Ljung-Box Test:\n",
    "   - Tests the null hypothesis that residuals are independently distributed\n",
    "   - p-value > 0.05 suggests no significant autocorrelation (good)\n",
    "   - p-value â‰¤ 0.05 suggests residuals still contain autocorrelation (problematic)\n",
    "\n",
    "3. Information Criteria:\n",
    "   - AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) balance model fit and complexity\n",
    "   - Lower values indicate better models\n",
    "   - BIC penalizes model complexity more heavily than AIC\n",
    "   - Models with the lowest AIC/BIC are generally preferred\n",
    "\n",
    "If diagnostic checks reveal issues (e.g., autocorrelated residuals), the model specification should be reconsidered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146de68",
   "metadata": {},
   "source": [
    "## 7. Model Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bfa452",
   "metadata": {},
   "source": [
    "Model Comparison concept not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare model performance on the test set\n",
    "models = ['ARIMA(1,1,1)', f'Auto ARIMA{best_order}', 'SARIMAX(1,1,1)']\n",
    "rmse_values = [arima_rmse, auto_arima_rmse, sarimax_rmse]\n",
    "mae_values = [arima_mae, auto_arima_mae, sarimax_mae]\n",
    "\n",
    "# Create a comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'RMSE': rmse_values,\n",
    "    'MAE': mae_values\n",
    "})\n",
    "print(\"Model Performance Comparison (Test Set):\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Plot the forecasts from all models\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train_ts, label='Training Data', alpha=0.3)\n",
    "plt.plot(test_ts, label='Actual Test Data')\n",
    "plt.plot(test_ts.index, arima_forecast, label='ARIMA Forecast')\n",
    "plt.plot(test_ts.index, auto_arima_forecast, label='Auto ARIMA Forecast')\n",
    "plt.plot(test_ts.index, sarimax_forecast, label='SARIMAX Forecast')\n",
    "plt.title('Forecast Comparison of Different Models')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify the best performing model\n",
    "best_model_idx = rmse_values.index(min(rmse_values))\n",
    "print(f\"\\nBest performing model based on RMSE: {models[best_model_idx]}\")\n",
    "print(f\"RMSE: {rmse_values[best_model_idx]:.4f}, MAE: {mae_values[best_model_idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd03bd3",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "\n",
    "Model comparison helps identify the most suitable model for the specific time series:\n",
    "\n",
    "1. Performance Metrics:\n",
    "   - RMSE (Root Mean Squared Error): Emphasizes larger errors\n",
    "   - MAE (Mean Absolute Error): Treats all errors equally\n",
    "   - Lower values indicate better performance\n",
    "\n",
    "2. Visual Comparison:\n",
    "   - Comparing forecasts visually can reveal patterns that metrics might miss\n",
    "   - Some models might perform better during specific market conditions\n",
    "\n",
    "3. Model Selection Considerations:\n",
    "   - Performance metrics (RMSE, MAE)\n",
    "   - Model complexity and interpretability\n",
    "   - Information criteria (AIC, BIC)\n",
    "   - Computational efficiency\n",
    "   - Domain knowledge and specific requirements\n",
    "\n",
    "4. Trade-offs:\n",
    "   - Simpler models (e.g., ARIMA) may be more interpretable but less accurate\n",
    "   - Complex models may fit better but risk overfitting\n",
    "   - Including exogenous variables (SARIMAX) can improve performance if the variables have predictive power\n",
    "\n",
    "The best model depends on the specific forecasting goals and constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca3b22",
   "metadata": {},
   "source": [
    "## Overall Findings & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddcc78",
   "metadata": {},
   "source": [
    "\n",
    "Based on our analysis of time series models for stock price forecasting:\n",
    "\n",
    "1. Model Selection:\n",
    "   - ARIMA models provide a solid baseline for time series forecasting\n",
    "   - Auto ARIMA can efficiently identify appropriate model orders\n",
    "   - SARIMAX can incorporate external factors that may influence stock prices\n",
    "   - GARCH models are valuable for volatility forecasting and risk assessment\n",
    "\n",
    "2. Key Insights:\n",
    "   - Stock prices typically require differencing to achieve stationarity\n",
    "   - Low-order ARIMA models often perform well for stock price forecasting\n",
    "   - Trading volume can provide additional information as an exogenous variable\n",
    "   - Volatility clustering is effectively captured by GARCH models\n",
    "\n",
    "3. Practical Recommendations:\n",
    "   - Start with simple models (e.g., ARIMA) as a baseline\n",
    "   - Use diagnostic checks to validate model assumptions\n",
    "   - Consider domain knowledge when selecting exogenous variables\n",
    "   - Combine mean models (ARIMA/SARIMAX) with volatility models (GARCH) for comprehensive analysis\n",
    "   - Regularly retrain models as new data becomes available\n",
    "\n",
    "4. Limitations:\n",
    "   - Time series models primarily capture patterns in historical data\n",
    "   - Unexpected events and market shocks are difficult to predict\n",
    "   - Stock prices are influenced by many factors beyond historical patterns\n",
    "   - Model performance can vary across different market conditions\n",
    "\n",
    "5. Next Steps:\n",
    "   - Explore machine learning approaches (Class 3)\n",
    "   - Consider ensemble methods combining multiple models\n",
    "   - Incorporate additional exogenous variables (economic indicators, sentiment data)\n",
    "   - Evaluate models across different time horizons and market conditions\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
