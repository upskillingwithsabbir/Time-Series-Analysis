{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5606a35",
   "metadata": {},
   "source": [
    "# Class 3: Time Series Analysis with ML Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a4ef5",
   "metadata": {},
   "source": [
    "This notebook explores Machine Learning approaches for time series forecasting, focusing on Facebook Prophet and XGBoost. We will also discuss appropriate train-test split strategies for time series data and compare the results with traditional statistical methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf4285",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cc1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 3: Time Series Analysis with ML Approach - Python Demonstrations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # Ignore harmless warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b117a",
   "metadata": {},
   "source": [
    "## 1. Load Data and Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b44e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 1. Loading Data ---\")\n",
    "data_file = \"/home/ubuntu/aapl_stock_data_10y.csv\"\n",
    "df = pd.read_csv(data_file, index_col='Date', parse_dates=True)\n",
    "\n",
    "# Use Adjusted Close price\n",
    "ts = df['Adj Close'].copy()\n",
    "\n",
    "# Split data: Train (first 9 years), Test (last 1 year approx)\n",
    "# ~252 trading days per year\n",
    "train_size = len(ts) - 252\n",
    "train_ts, test_ts = ts[:train_size], ts[train_size:]\n",
    "\n",
    "print(f\"Train set size: {len(train_ts)}\")\n",
    "print(f\"Test set size: {len(test_ts)}\")\n",
    "\n",
    "# Initialize variables for metrics\n",
    "prophet_rmse, prophet_mae = np.nan, np.nan\n",
    "xgb_rmse, xgb_mae = np.nan, np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5d475",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "**Output:** The code loads the AAPL dataset, selects the 'Adj Close' price, and splits the data into training and testing sets according to the time series split strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e004da8",
   "metadata": {},
   "source": [
    "## 2. Facebook Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 2. Fitting Prophet Model ---\")\n",
    "\n",
    "# Prepare data for Prophet (requires columns 'ds' and 'y')\n",
    "prophet_train_df = train_ts.reset_index()\n",
    "prophet_train_df.columns = ['ds', 'y']\n",
    "\n",
    "try:\n",
    "    # Instantiate and fit Prophet model\n",
    "    # Prophet automatically detects trend changes and seasonality\n",
    "    prophet_model = Prophet(daily_seasonality=False, weekly_seasonality=True, yearly_seasonality=True, \n",
    "                            changepoint_prior_scale=0.05) # Default is 0.05\n",
    "    prophet_model.fit(prophet_train_df)\n",
    "\n",
    "    # Create future dataframe for predictions\n",
    "    future_dates = prophet_model.make_future_dataframe(periods=len(test_ts), freq='B') # 'B' for business day frequency\n",
    "    # Filter future_dates to match the test set index exactly\n",
    "    future_dates = future_dates[future_dates['ds'].isin(test_ts.index)]\n",
    "\n",
    "    # Make predictions\n",
    "    prophet_forecast = prophet_model.predict(future_dates)\n",
    "\n",
    "    # Extract prediction ('yhat')\n",
    "    prophet_pred = prophet_forecast['yhat'].values\n",
    "    prophet_pred = pd.Series(prophet_pred, index=test_ts.index)\n",
    "\n",
    "    # Plot forecast vs actual\n",
    "    fig = prophet_model.plot(prophet_forecast)\n",
    "    plt.plot(test_ts.index, test_ts, '.r', label='Actual Test Data')\n",
    "    plt.title('Prophet Forecast vs Actuals')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"/home/ubuntu/plot_15_prophet_forecast.png\")\n",
    "    plt.close(fig) # Close the figure created by prophet\n",
    "    print(\"Saved plot: plot_15_prophet_forecast.png\")\n",
    "\n",
    "    # Plot components (optional, good for lecture)\n",
    "    fig_comp = prophet_model.plot_components(prophet_forecast)\n",
    "    plt.savefig(\"/home/ubuntu/plot_16_prophet_components.png\")\n",
    "    plt.close(fig_comp)\n",
    "    print(\"Saved plot: plot_16_prophet_components.png\")\n",
    "\n",
    "    # Performance Metrics\n",
    "    prophet_rmse = np.sqrt(mean_squared_error(test_ts, prophet_pred))\n",
    "    prophet_mae = mean_absolute_error(test_ts, prophet_pred)\n",
    "    print(f\"Prophet RMSE: {prophet_rmse:.4f}\")\n",
    "    print(f\"Prophet MAE: {prophet_mae:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error fitting Prophet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff09da",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "*   **Process:** The Prophet model was instantiated with default yearly and weekly seasonality enabled. The data was formatted correctly (ds, y), and the model was fitted to the training data.\n",
    "*   **Prediction Failure:** An error occurred during the prediction phase: \"Length of values (241) does not match length of index (252)\". This mismatch likely happened because Prophet's `make_future_dataframe` with `freq='B'` (business days) generated a different number of dates than were present in the actual `test_ts` index over the same period (which might include holidays where the market was closed but Prophet predicted a value, or vice-versa). \n",
    "*   **Troubleshooting (for lecture):** This is a valuable teaching point about handling date indices carefully, especially when dealing with business day frequencies and potential holidays. Solutions could involve:\n",
    "    *   Ensuring the `future_dates` dataframe generated by Prophet perfectly aligns with the target test set index *before* prediction.\n",
    "    *   Using the test set's actual dates directly to create the `future_dates` dataframe instead of relying solely on `make_future_dataframe` with a frequency.\n",
    "    *   Post-processing the forecast to align it with the test index (e.g., reindexing).\n",
    "*   **Performance:** Due to the prediction error, RMSE and MAE could not be calculated for Prophet.\n",
    "*   **Components Plot (`plot_16_prophet_components.png`):** Although the forecast failed on the test set, the components plot generated from the training fit is still useful. It would typically show the overall trend detected by Prophet, as well as the estimated yearly and weekly seasonal patterns learned from the data. This helps in understanding the model's internal view of the time series structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19799fe",
   "metadata": {},
   "source": [
    "## 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e9eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 3. Fitting XGBoost Model ---\")\n",
    "\n",
    "# Feature Engineering for XGBoost\n",
    "def create_features(df, label=None):\n",
    "    \"\"\" Creates time series features from datetime index. \"\"\"\n",
    "    df = df.copy()\n",
    "    df['date'] = df.index\n",
    "    df['hour'] = df['date'].dt.hour # Will be 0 for daily data\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    df['dayofmonth'] = df['date'].dt.day\n",
    "    df['weekofyear'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    \n",
    "    # Add Lag features\n",
    "    for lag in [1, 5, 10, 21]: # Lag by 1 day, 1 week, 2 weeks, 1 month (approx)\n",
    "        df[f'lag_{lag}'] = df['Adj Close'].shift(lag)\n",
    "        \n",
    "    # Add Rolling Mean features\n",
    "    for window in [5, 21]: # Rolling mean over 1 week, 1 month\n",
    "        df[f'rolling_mean_{window}'] = df['Adj Close'].shift(1).rolling(window=window).mean()\n",
    "\n",
    "    X = df[['hour', 'dayofweek', 'quarter', 'month', 'year',\n",
    "              'dayofyear', 'dayofmonth', 'weekofyear'] + [f'lag_{lag}' for lag in [1, 5, 10, 21]] + \\\n",
    "             [f'rolling_mean_{window}' for window in [5, 21]]]\n",
    "    if label:\n",
    "        y = df[label]\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "# Create features for the entire dataset first to handle lags correctly\n",
    "df_with_features = df.copy()\n",
    "df_with_features['Adj Close'] = ts # Ensure the target column exists\n",
    "X_all, y_all = create_features(df_with_features, label='Adj Close')\n",
    "\n",
    "# Split features into train/test based on original index\n",
    "X_train, y_train = X_all.loc[train_ts.index], y_all.loc[train_ts.index]\n",
    "X_test, y_test = X_all.loc[test_ts.index], y_all.loc[test_ts.index]\n",
    "\n",
    "# Drop rows with NaNs created by lag/rolling features (mostly at the beginning of train set)\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "# Check if test set has NaNs (shouldn't if lags are smaller than test set size)\n",
    "if X_test.isnull().values.any():\n",
    "    print(\"Warning: NaNs found in X_test, potentially due to lag features. Dropping NaNs.\")\n",
    "    test_nan_indices = X_test[X_test.isnull().any(axis=1)].index\n",
    "    X_test = X_test.dropna()\n",
    "    y_test = y_test.loc[X_test.index]\n",
    "    # Adjust original test_ts to match the rows kept in X_test/y_test\n",
    "    test_ts = test_ts.drop(test_nan_indices)\n",
    "    print(f\"Adjusted test set size after dropping NaNs: {len(test_ts)}\")\n",
    "\n",
    "try:\n",
    "    # Instantiate and fit XGBoost model\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=1000, # Number of boosting rounds\n",
    "        learning_rate=0.01,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        early_stopping_rounds=50, # Stop if validation score doesn't improve\n",
    "        n_jobs=-1 # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # Use last part of training set as validation for early stopping\n",
    "    # Ensure validation set size matches test set size for consistency if possible\n",
    "    val_size = len(y_test) # Use size of potentially reduced test set\n",
    "    X_train_part, X_val_part = X_train[:-val_size], X_train[-val_size:]\n",
    "    y_train_part, y_val_part = y_train[:-val_size], y_train[-val_size:]\n",
    "\n",
    "    xgb_model.fit(X_train_part, y_train_part, \n",
    "                  eval_set=[(X_val_part, y_val_part)], \n",
    "                  verbose=False) # Set verbose=True to see training progress\n",
    "\n",
    "    # Make predictions\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    xgb_pred = pd.Series(xgb_pred, index=y_test.index) # Use y_test index which might have dropped NaNs\n",
    "\n",
    "    # Plot forecast vs actual\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Plot original train/test for context, using potentially adjusted test_ts\n",
    "    plt.plot(train_ts.index, train_ts, label='Train') \n",
    "    plt.plot(test_ts.index, test_ts, label='Test') \n",
    "    plt.plot(xgb_pred.index, xgb_pred, label='XGBoost Forecast', alpha=0.8)\n",
    "    plt.title('XGBoost Forecast vs Actuals')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"/home/ubuntu/plot_17_xgboost_forecast.png\")\n",
    "    plt.close()\n",
    "    print(\"Saved plot: plot_17_xgboost_forecast.png\")\n",
    "\n",
    "    # Performance Metrics\n",
    "    xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
    "    xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
    "    print(f\"XGBoost RMSE: {xgb_rmse:.4f}\")\n",
    "    print(f\"XGBoost MAE: {xgb_mae:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error fitting XGBoost: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea9d2b4",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "*   **Process:** An XGBoost Regressor was used. Feature engineering was crucial, creating time-based features (day of week, month, year, etc.) and lag features (past values of the price) and rolling mean features.\n",
    "*   **Feature Engineering:** Lags (1, 5, 10, 21 days) and rolling means (5, 21 days) were created. It's important to create these on the full dataset before splitting to avoid lookahead bias within the training set, and then carefully split X and y. NaNs introduced by these features at the start of the training data were dropped.\n",
    "*   **Training:** The model was trained using early stopping based on a validation set (taken from the end of the training data) to prevent overfitting.\n",
    "*   **Performance (Test Set):**\n",
    "    *   RMSE: 53.3728\n",
    "    *   MAE: 50.9893\n",
    "*   **Interpretation:** The XGBoost model produced a forecast, but its performance (RMSE ~53.4, MAE ~51.0) was significantly worse than the simple ARIMA(1,1,1) model (RMSE ~35.0, MAE ~31.6) and the SARIMAX model (RMSE ~35.3, MAE ~31.9) on this test set. This highlights that more complex ML models are not automatically better for time series forecasting, especially with default settings or basic feature engineering. The performance heavily depends on the quality and relevance of the features created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a52bb",
   "metadata": {},
   "source": [
    "## 4. Comparison (Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6029c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 4. ML Model Performance Comparison (Test Set) ---\")\n",
    "print(f\"Prophet RMSE: {prophet_rmse:.4f}, MAE: {prophet_mae:.4f}\")\n",
    "print(f\"XGBoost RMSE: {xgb_rmse:.4f}, MAE: {xgb_mae:.4f}\")\n",
    "print(\"Compare these metrics with those from Class 2 (Statistical Models).\")\n",
    "\n",
    "print(\"\\nClass 3 Demonstrations Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892d2d3f",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "**ML Model Performance Comparison (Test Set):**\n",
    "\n",
    "Prophet RMSE: [prophet_rmse:.4f], MAE: [prophet_mae:.4f]\n",
    "XGBoost RMSE: [xgb_rmse:.4f], MAE: [xgb_mae:.4f]\n",
    "print(\"Compare these metrics with those from Class 2 (Statistical Models).\n",
    "\n",
    "print(\"\\nClass 3 Demonstrations Complete.\n",
    "\n",
    "*Note: Compare these metrics with those from Class 2 (Statistical Models). See final comparison section below.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
