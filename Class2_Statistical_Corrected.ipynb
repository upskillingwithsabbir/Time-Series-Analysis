{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89bc16bb",
   "metadata": {},
   "source": [
    "# Class 2: Time Series Analysis with Statistical Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61498070",
   "metadata": {},
   "source": [
    "This notebook delves into statistical models commonly used for time series analysis and forecasting. We will cover AR, MA, ARMA, ARIMA, SARIMAX, and GARCH models, along with model selection criteria and diagnostic checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9cc31",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 2: Time Series Analysis with Statistical Modeling - Python Demonstrations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import pmdarima as pm\n",
    "from arch import arch_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # Ignore harmless warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831bcdb7",
   "metadata": {},
   "source": [
    "## 1. Load Data and Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbb8c9",
   "metadata": {},
   "source": [
    "*Concept placeholder* \n",
    " (No specific concept outline found for this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f11f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 1. Loading Data ---\")\n",
    "data_file = \"/home/ubuntu/aapl_stock_data_10y.csv\"\n",
    "df = pd.read_csv(data_file, index_col='Date', parse_dates=True)\n",
    "\n",
    "# Use Adjusted Close price\n",
    "ts = df['Adj Close'].copy()\n",
    "# Use Volume as an exogenous variable example\n",
    "exog = df['Volume'].copy()\n",
    "\n",
    "# Use log returns for GARCH modeling (common practice)\n",
    "log_returns = np.log(ts / ts.shift(1)).dropna()\n",
    "\n",
    "# Split data: Train (first 9 years), Test (last 1 year approx)\n",
    "# ~252 trading days per year\n",
    "train_size = len(ts) - 252\n",
    "train_ts, test_ts = ts[:train_size], ts[train_size:]\n",
    "train_exog, test_exog = exog[:train_size], exog[train_size:]\n",
    "train_log_returns, test_log_returns = log_returns[:train_size], log_returns[train_size:]\n",
    "\n",
    "print(f\"Train set size: {len(train_ts)}\")\n",
    "print(f\"Test set size: {len(test_ts)}\")\n",
    "\n",
    "# Initialize variables for metrics to avoid NameError if a model fails\n",
    "arima_rmse, arima_mae = np.nan, np.nan\n",
    "auto_arima_rmse, auto_arima_mae = np.nan, np.nan\n",
    "sarimax_rmse, sarimax_mae = np.nan, np.nan\n",
    "best_order = (0,0,0) # Default order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351ce251",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "*Interpretation placeholder* \n",
    " (No specific interpretation found for this section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4b8e9",
   "metadata": {},
   "source": [
    "## 2. ARIMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddc6b9e",
   "metadata": {},
   "source": [
    "*Concept placeholder* \n",
    " (No specific concept outline found for this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2237d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 2. Fitting ARIMA Model ---\")\n",
    "# Based on Class 1, the series needed differencing (d=1).\n",
    "# ACF/PACF of differenced series can suggest p, q. Let's try ARIMA(1,1,1) as a starting point.\n",
    "# Note: Order selection is iterative. ACF/PACF gives hints.\n",
    "\n",
    "try:\n",
    "    arima_model = ARIMA(train_ts, order=(1, 1, 1))\n",
    "    arima_fit = arima_model.fit()\n",
    "    print(arima_fit.summary())\n",
    "\n",
    "    # Forecast\n",
    "    arima_pred = arima_fit.predict(start=len(train_ts), end=len(ts)-1)\n",
    "\n",
    "    # Plot forecast vs actual\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_ts.index, train_ts, label='Train')\n",
    "    plt.plot(test_ts.index, test_ts, label='Test')\n",
    "    plt.plot(test_ts.index, arima_pred, label='ARIMA(1,1,1) Forecast')\n",
    "    plt.title('ARIMA(1,1,1) Forecast vs Actuals')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"/home/ubuntu/plot_09_arima_forecast.png\")\n",
    "    plt.close()\n",
    "    print(\"Saved plot: plot_09_arima_forecast.png\")\n",
    "\n",
    "    # Performance Metrics\n",
    "    arima_rmse = np.sqrt(mean_squared_error(test_ts, arima_pred))\n",
    "    arima_mae = mean_absolute_error(test_ts, arima_pred)\n",
    "    print(f\"ARIMA(1,1,1) RMSE: {arima_rmse:.4f}\")\n",
    "    print(f\"ARIMA(1,1,1) MAE: {arima_mae:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error fitting ARIMA(1,1,1): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5238ee",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "*   **ARIMA(1,1,1) Summary:**\n",
    "    *   The summary showed significant coefficients for both the AR1 (autoregressive term at lag 1) and MA1 (moving average term at lag 1) components (p-values << 0.05). This supports the inclusion of these terms in the model based on the training data.\n",
    "    *   The `sigma2` value represents the estimated variance of the residuals.\n",
    "*   **Auto ARIMA Summary:**\n",
    "    *   The `auto_arima` trace showed the stepwise search process, comparing different model orders based on AIC. It converged to ARIMA(1,1,2) as the best model for the training data (AIC: 9225.391).\n",
    "    *   The summary for the selected ARIMA(1,1,2) model showed significant coefficients for AR1, MA1, and MA2 terms.\n",
    "*   **SARIMAX(1,1,1) Summary:**\n",
    "    *   The coefficient for the exogenous variable `x1` (Volume) was statistically significant (p=0.005). This indicates that, within the training data, volume had a statistically significant relationship with the differenced adjusted close price, even though it didn't improve the test set forecast accuracy in this instance. The coefficient was negative, suggesting a slight inverse relationship in this specific model context.\n",
    "    *   AR1 and MA1 terms were also highly significant, similar to the ARIMA model.\n",
    "    *   A warning about the covariance matrix being singular or near-singular suggests potential multicollinearity or numerical instability issues, which might warrant further investigation or model simplification.\n",
    "*   **GARCH(1,1) Summary (on Log Returns):**\n",
    "    *   The model was fitted to the log returns to analyze volatility.\n",
    "    *   The `mu` (mean) coefficient was significant but small, indicating a slight positive drift in daily log returns.\n",
    "    *   The volatility parameters `alpha[1]` (ARCH term) and `beta[1]` (GARCH term) were both highly significant (p-values << 0.05).\n",
    "    *   The sum of `alpha[1]` (0.10) and `beta[1]` (0.88) is close to 1 (0.98). This indicates high persistence in volatility – meaning that periods of high volatility tend to be followed by more high volatility, and periods of low volatility by low volatility (volatility clustering), a well-known characteristic of financial time series.\n",
    "    *   The plot `plot_12_garch_volatility.png` visually confirms this, showing periods where the estimated conditional volatility spikes and remains elevated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610a32f",
   "metadata": {},
   "source": [
    "## 3. AUTO ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53354f18",
   "metadata": {},
   "source": [
    "*Concept placeholder* \n",
    " (No specific concept outline found for this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195942cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 3. Fitting AUTO ARIMA Model ---\")\n",
    "# Automatically find best ARIMA model\n",
    "try:\n",
    "    auto_arima_model = pm.auto_arima(train_ts, \n",
    "                                     start_p=1, start_q=1,\n",
    "                                     test='adf', # use adf test to find optimal 'd'\n",
    "                                     max_p=3, max_q=3, # maximum p and q\n",
    "                                     m=1, # Non-seasonal\n",
    "                                     d=None, # let model determine 'd'\n",
    "                                     seasonal=False, # No Seasonality\n",
    "                                     start_P=0, D=0, \n",
    "                                     trace=True,\n",
    "                                     error_action='ignore', \n",
    "                                     suppress_warnings=True, \n",
    "                                     stepwise=True) # Use stepwise algorithm\n",
    "\n",
    "    print(auto_arima_model.summary())\n",
    "    best_order = auto_arima_model.order # Store the best order found\n",
    "\n",
    "    # Forecast with Auto ARIMA\n",
    "    auto_arima_pred = auto_arima_model.predict(n_periods=len(test_ts))\n",
    "    auto_arima_pred = pd.Series(auto_arima_pred, index=test_ts.index)\n",
    "\n",
    "    # Plot forecast vs actual\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_ts.index, train_ts, label='Train')\n",
    "    plt.plot(test_ts.index, test_ts, label='Test')\n",
    "    plt.plot(test_ts.index, auto_arima_pred, label='Auto ARIMA Forecast')\n",
    "    plt.title('Auto ARIMA Forecast vs Actuals')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"/home/ubuntu/plot_10_auto_arima_forecast.png\")\n",
    "    plt.close()\n",
    "    print(\"Saved plot: plot_10_auto_arima_forecast.png\")\n",
    "\n",
    "    # Performance Metrics\n",
    "    auto_arima_rmse = np.sqrt(mean_squared_error(test_ts, auto_arima_pred))\n",
    "    auto_arima_mae = mean_absolute_error(test_ts, auto_arima_pred)\n",
    "    print(f\"Auto ARIMA RMSE: {auto_arima_rmse:.4f}\")\n",
    "    print(f\"Auto ARIMA MAE: {auto_arima_mae:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error fitting Auto ARIMA: {e}\")\n",
    "    # Use default order if auto_arima fails\n",
    "    best_order = (1, 1, 1) # Fallback if auto arima fails\n",
    "    print(f\"Falling back to order {best_order} for SARIMAX due to Auto ARIMA error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85576d6",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "*   **ARIMA(1,1,1) Summary:**\n",
    "    *   The summary showed significant coefficients for both the AR1 (autoregressive term at lag 1) and MA1 (moving average term at lag 1) components (p-values << 0.05). This supports the inclusion of these terms in the model based on the training data.\n",
    "    *   The `sigma2` value represents the estimated variance of the residuals.\n",
    "*   **Auto ARIMA Summary:**\n",
    "    *   The `auto_arima` trace showed the stepwise search process, comparing different model orders based on AIC. It converged to ARIMA(1,1,2) as the best model for the training data (AIC: 9225.391).\n",
    "    *   The summary for the selected ARIMA(1,1,2) model showed significant coefficients for AR1, MA1, and MA2 terms.\n",
    "*   **SARIMAX(1,1,1) Summary:**\n",
    "    *   The coefficient for the exogenous variable `x1` (Volume) was statistically significant (p=0.005). This indicates that, within the training data, volume had a statistically significant relationship with the differenced adjusted close price, even though it didn't improve the test set forecast accuracy in this instance. The coefficient was negative, suggesting a slight inverse relationship in this specific model context.\n",
    "    *   AR1 and MA1 terms were also highly significant, similar to the ARIMA model.\n",
    "    *   A warning about the covariance matrix being singular or near-singular suggests potential multicollinearity or numerical instability issues, which might warrant further investigation or model simplification.\n",
    "*   **GARCH(1,1) Summary (on Log Returns):**\n",
    "    *   The model was fitted to the log returns to analyze volatility.\n",
    "    *   The `mu` (mean) coefficient was significant but small, indicating a slight positive drift in daily log returns.\n",
    "    *   The volatility parameters `alpha[1]` (ARCH term) and `beta[1]` (GARCH term) were both highly significant (p-values << 0.05).\n",
    "    *   The sum of `alpha[1]` (0.10) and `beta[1]` (0.88) is close to 1 (0.98). This indicates high persistence in volatility – meaning that periods of high volatility tend to be followed by more high volatility, and periods of low volatility by low volatility (volatility clustering), a well-known characteristic of financial time series.\n",
    "    *   The plot `plot_12_garch_volatility.png` visually confirms this, showing periods where the estimated conditional volatility spikes and remains elevated.\n",
    "\n",
    "*Note: Auto ARIMA failed during the prediction phase in the demonstration code.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4ce5d",
   "metadata": {},
   "source": [
    "## 4. SARIMAX Model (Example with Exogenous Variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d38ea2",
   "metadata": {},
   "source": [
    "*Concept placeholder* \n",
    " (No specific concept outline found for this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03550913",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 4. Fitting SARIMAX Model (with Exogenous Variable) ---\")\n",
    "# Using orders from Auto ARIMA (or fallback), add Volume as exogenous variable\n",
    "# Note: Seasonality (P,D,Q,m) is set to 0 here as auto_arima found none.\n",
    "\n",
    "try:\n",
    "    # Ensure exog variables are numpy arrays\n",
    "    train_exog_np = train_exog.values.reshape(-1, 1)\n",
    "    test_exog_np = test_exog.values.reshape(-1, 1)\n",
    "\n",
    "    sarimax_model = SARIMAX(train_ts, \n",
    "                            exog=train_exog_np, \n",
    "                            order=best_order, \n",
    "                            seasonal_order=(0, 0, 0, 0), # No seasonality assumed here\n",
    "                            enforce_stationarity=False, \n",
    "                            enforce_invertibility=False)\n",
    "    sarimax_fit = sarimax_model.fit(disp=False)\n",
    "    print(sarimax_fit.summary())\n",
    "\n",
    "    # Forecast with exogenous variables\n",
    "    sarimax_pred = sarimax_fit.predict(start=len(train_ts), end=len(ts)-1, exog=test_exog_np)\n",
    "\n",
    "    # Plot forecast vs actual\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_ts.index, train_ts, label='Train')\n",
    "    plt.plot(test_ts.index, test_ts, label='Test')\n",
    "    plt.plot(test_ts.index, sarimax_pred, label='SARIMAX Forecast')\n",
    "    plt.title(f'SARIMAX{best_order} Forecast vs Actuals (Exog: Volume)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"/home/ubuntu/plot_11_sarimax_forecast.png\")\n",
    "    plt.close()\n",
    "    print(\"Saved plot: plot_11_sarimax_forecast.png\")\n",
    "\n",
    "    # Performance Metrics\n",
    "    sarimax_rmse = np.sqrt(mean_squared_error(test_ts, sarimax_pred))\n",
    "    sarimax_mae = mean_absolute_error(test_ts, sarimax_pred)\n",
    "    print(f\"SARIMAX{best_order} RMSE: {sarimax_rmse:.4f}\")\n",
    "    print(f\"SARIMAX{best_order} MAE: {sarimax_mae:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error fitting SARIMAX: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870cc09a",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "*   **ARIMA(1,1,1) Summary:**\n",
    "    *   The summary showed significant coefficients for both the AR1 (autoregressive term at lag 1) and MA1 (moving average term at lag 1) components (p-values << 0.05). This supports the inclusion of these terms in the model based on the training data.\n",
    "    *   The `sigma2` value represents the estimated variance of the residuals.\n",
    "*   **Auto ARIMA Summary:**\n",
    "    *   The `auto_arima` trace showed the stepwise search process, comparing different model orders based on AIC. It converged to ARIMA(1,1,2) as the best model for the training data (AIC: 9225.391).\n",
    "    *   The summary for the selected ARIMA(1,1,2) model showed significant coefficients for AR1, MA1, and MA2 terms.\n",
    "*   **SARIMAX(1,1,1) Summary:**\n",
    "    *   The coefficient for the exogenous variable `x1` (Volume) was statistically significant (p=0.005). This indicates that, within the training data, volume had a statistically significant relationship with the differenced adjusted close price, even though it didn't improve the test set forecast accuracy in this instance. The coefficient was negative, suggesting a slight inverse relationship in this specific model context.\n",
    "    *   AR1 and MA1 terms were also highly significant, similar to the ARIMA model.\n",
    "    *   A warning about the covariance matrix being singular or near-singular suggests potential multicollinearity or numerical instability issues, which might warrant further investigation or model simplification.\n",
    "*   **GARCH(1,1) Summary (on Log Returns):**\n",
    "    *   The model was fitted to the log returns to analyze volatility.\n",
    "    *   The `mu` (mean) coefficient was significant but small, indicating a slight positive drift in daily log returns.\n",
    "    *   The volatility parameters `alpha[1]` (ARCH term) and `beta[1]` (GARCH term) were both highly significant (p-values << 0.05).\n",
    "    *   The sum of `alpha[1]` (0.10) and `beta[1]` (0.88) is close to 1 (0.98). This indicates high persistence in volatility – meaning that periods of high volatility tend to be followed by more high volatility, and periods of low volatility by low volatility (volatility clustering), a well-known characteristic of financial time series.\n",
    "    *   The plot `plot_12_garch_volatility.png` visually confirms this, showing periods where the estimated conditional volatility spikes and remains elevated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c217d",
   "metadata": {},
   "source": [
    "## 5. ARCH/GARCH Model for Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754da4db",
   "metadata": {},
   "source": [
    "*Concept placeholder* \n",
    " (No specific concept outline found for this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c267b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 5. Fitting GARCH Model on Log Returns ---\")\n",
    "# Model volatility of log returns\n",
    "# Common choice: GARCH(1,1)\n",
    "try:\n",
    "    garch_model = arch_model(train_log_returns, vol='Garch', p=1, q=1)\n",
    "    garch_fit = garch_model.fit(disp='off') # Turn off verbose fitting output\n",
    "    print(garch_fit.summary())\n",
    "\n",
    "    # Plot conditional volatility\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(garch_fit.conditional_volatility, label='Conditional Volatility')\n",
    "    plt.title('GARCH(1,1) Conditional Volatility of AAPL Log Returns')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Volatility')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"/home/ubuntu/plot_12_garch_volatility.png\")\n",
    "    plt.close()\n",
    "    print(\"Saved plot: plot_12_garch_volatility.png\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fitting GARCH: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d828f9a",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "*   **ARIMA(1,1,1) Summary:**\n",
    "    *   The summary showed significant coefficients for both the AR1 (autoregressive term at lag 1) and MA1 (moving average term at lag 1) components (p-values << 0.05). This supports the inclusion of these terms in the model based on the training data.\n",
    "    *   The `sigma2` value represents the estimated variance of the residuals.\n",
    "*   **Auto ARIMA Summary:**\n",
    "    *   The `auto_arima` trace showed the stepwise search process, comparing different model orders based on AIC. It converged to ARIMA(1,1,2) as the best model for the training data (AIC: 9225.391).\n",
    "    *   The summary for the selected ARIMA(1,1,2) model showed significant coefficients for AR1, MA1, and MA2 terms.\n",
    "*   **SARIMAX(1,1,1) Summary:**\n",
    "    *   The coefficient for the exogenous variable `x1` (Volume) was statistically significant (p=0.005). This indicates that, within the training data, volume had a statistically significant relationship with the differenced adjusted close price, even though it didn't improve the test set forecast accuracy in this instance. The coefficient was negative, suggesting a slight inverse relationship in this specific model context.\n",
    "    *   AR1 and MA1 terms were also highly significant, similar to the ARIMA model.\n",
    "    *   A warning about the covariance matrix being singular or near-singular suggests potential multicollinearity or numerical instability issues, which might warrant further investigation or model simplification.\n",
    "*   **GARCH(1,1) Summary (on Log Returns):**\n",
    "    *   The model was fitted to the log returns to analyze volatility.\n",
    "    *   The `mu` (mean) coefficient was significant but small, indicating a slight positive drift in daily log returns.\n",
    "    *   The volatility parameters `alpha[1]` (ARCH term) and `beta[1]` (GARCH term) were both highly significant (p-values << 0.05).\n",
    "    *   The sum of `alpha[1]` (0.10) and `beta[1]` (0.88) is close to 1 (0.98). This indicates high persistence in volatility – meaning that periods of high volatility tend to be followed by more high volatility, and periods of low volatility by low volatility (volatility clustering), a well-known characteristic of financial time series.\n",
    "    *   The plot `plot_12_garch_volatility.png` visually confirms this, showing periods where the estimated conditional volatility spikes and remains elevated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba4b20",
   "metadata": {},
   "source": [
    "## 6. Model Diagnostics (Example: Auto ARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af538c8a",
   "metadata": {},
   "source": [
    "*Concept placeholder* \n",
    " (No specific concept outline found for this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d16f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 6. Diagnostic Checks (Example: Auto ARIMA) ---\")\n",
    "# Check if auto_arima_model exists and has residuals\n",
    "if 'auto_arima_model' in locals() and hasattr(auto_arima_model, 'resid'):\n",
    "    residuals = auto_arima_model.resid()\n",
    "    \n",
    "    # Plot Residuals\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(residuals)\n",
    "    plt.title('Auto ARIMA Residuals')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Residual Value')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"/home/ubuntu/plot_13_auto_arima_residuals.png\")\n",
    "    plt.close()\n",
    "    print(\"Saved plot: plot_13_auto_arima_residuals.png\")\n",
    "\n",
    "    # ACF/PACF of Residuals\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "    plot_acf(residuals, ax=axes[0], lags=40, title='ACF of Residuals')\n",
    "    plot_pacf(residuals, ax=axes[1], lags=40, title='PACF of Residuals')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"/home/ubuntu/plot_14_residual_acf_pacf.png\")\n",
    "    plt.close()\n",
    "    print(\"Saved plot: plot_14_residual_acf_pacf.png\")\n",
    "    print(\"Ideally, ACF/PACF of residuals should show no significant spikes.\")\n",
    "\n",
    "    # Ljung-Box Test\n",
    "    try:\n",
    "        ljung_box_result = acorr_ljungbox(residuals, lags=[20], return_df=True)\n",
    "        print(\"\\nLjung-Box Test on Residuals:\")\n",
    "        print(ljung_box_result)\n",
    "        print(\"If p-value > 0.05, we fail to reject H0 (residuals are independent/white noise).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not perform Ljung-Box test: {e}\")\n",
    "else:\n",
    "    print(\"Skipping Auto ARIMA diagnostics as the model did not fit successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1848fa",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "We examined the residuals from the fitted Auto ARIMA model (ARIMA(1,1,2)) to assess its adequacy on the training data.\n",
    "\n",
    "*   **Residual Plot (`plot_13_auto_arima_residuals.png`):** The residuals appear somewhat randomly distributed around zero, without obvious trends or strong patterns, which is desirable.\n",
    "*   **ACF/PACF Plots (`plot_14_residual_acf_pacf.png`):** Ideally, the ACF and PACF plots of the residuals should show no significant spikes outside the confidence bands for all lags greater than 0. While many spikes are within the bands, there might be a few borderline or slightly significant spikes, suggesting some autocorrelation might remain.\n",
    "*   **Ljung-Box Test:** This test formally checks if the residuals are independently distributed (i.e., resemble white noise). The null hypothesis (H0) is that the residuals are independent.\n",
    "    *   The test yielded a p-value of approximately 0.011 for lags up to 20.\n",
    "    *   Since the p-value (0.011) is less than the common significance level of 0.05, we **reject the null hypothesis**. This indicates that there is significant autocorrelation remaining in the residuals, and they do not behave like white noise.\n",
    "\n",
    "**Interpretation:** The diagnostic checks, particularly the Ljung-Box test, suggest that the Auto ARIMA(1,1,2) model, while being the best fit according to AIC on the training data, did not fully capture all the temporal dependencies. There is still structure left in the residuals. This could mean a more complex model (perhaps higher orders, different differencing, or incorporating seasonality if relevant) might be needed, or that the underlying process has complexities not easily captured by standard ARIMA models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e74534",
   "metadata": {},
   "source": [
    "## 7. Model Comparison (Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2924445f",
   "metadata": {},
   "source": [
    "*Concept placeholder* \n",
    " (No specific concept outline found for this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 7. Model Performance Comparison (Test Set) ---\")\n",
    "print(f\"ARIMA(1,1,1)   RMSE: {arima_rmse:.4f}, MAE: {arima_mae:.4f}\")\n",
    "print(f\"Auto ARIMA     RMSE: {auto_arima_rmse:.4f}, MAE: {auto_arima_mae:.4f}\")\n",
    "print(f\"SARIMAX{best_order}    RMSE: {sarimax_rmse:.4f}, MAE: {sarimax_mae:.4f}\")\n",
    "print(\"Note: Lower RMSE/MAE indicates better forecast accuracy on the test set.\")\n",
    "\n",
    "print(\"\\nClass 2 Demonstrations Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea1fa2",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "The primary goal of these models was to forecast the adjusted close price for the last year of the data (test set). We evaluated the forecasts using Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). Lower values indicate better accuracy.\n",
    "\n",
    "*   **ARIMA(1,1,1):**\n",
    "    *   RMSE: 35.0100\n",
    "    *   MAE: 31.5656\n",
    "*   **Auto ARIMA:**\n",
    "    *   The `pmdarima.auto_arima` function successfully identified an optimal order (1,1,2) based on the AIC criterion during its search process. However, it encountered an error (\"Input contains NaN\") during the prediction phase on the test set. This resulted in NaN values for RMSE and MAE. This failure often indicates issues with how the model handles data transformations (like differencing) at the prediction boundary or potential NaNs introduced during feature engineering (though none were explicitly added here). Further investigation would be needed in a real-world scenario (e.g., checking internal steps, trying different `pmdarima` versions or settings).\n",
    "*   **SARIMAX(1,1,1) (with Volume as Exogenous Variable):**\n",
    "    *   Since Auto ARIMA failed to provide a reliable forecast, we used the fallback order (1,1,1) for the SARIMAX model, incorporating the daily trading volume as an external predictor.\n",
    "    *   RMSE: 35.2970\n",
    "    *   MAE: 31.8694\n",
    "\n",
    "**Interpretation:**\n",
    "Comparing the successful models, the simple ARIMA(1,1,1) model performed slightly better than the SARIMAX(1,1,1) model with volume as an exogenous variable on this specific test set, having marginally lower RMSE and MAE. This suggests that, for this particular dataset and model configuration, adding volume did not improve the one-step-ahead forecast accuracy for the price itself. It is important to note that stock price forecasting is notoriously difficult, and these relatively high error values (compared to the price scale) are common. The value of exogenous variables might be more apparent in different contexts or with different modeling approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e8fa86",
   "metadata": {},
   "source": [
    "## Overall Findings & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa28924f",
   "metadata": {},
   "source": [
    "*   **Process:** The demonstration successfully walked through loading, splitting, modeling (ARIMA, Auto ARIMA, SARIMAX, GARCH), forecasting, evaluating (RMSE, MAE), and diagnosing time series models.\n",
    "*   **Stationarity:** The initial ADF test confirmed the non-stationarity of the raw price series, necessitating differencing (d=1) for ARIMA-based models.\n",
    "*   **Model Selection:** Auto ARIMA is a useful tool for automatically finding potentially good ARIMA orders based on information criteria (AIC/BIC), but it's not foolproof (as seen by the prediction failure and residual issues). Manual inspection of ACF/PACF plots remains important.\n",
    "*   **Exogenous Variables:** SARIMAX allows incorporating external factors. While Volume was statistically significant in the training fit, it didn't improve test set price forecasts here. The impact of exogenous variables can be highly context-dependent.\n",
    "*   **Volatility Modeling:** GARCH models are essential for analyzing and forecasting the *volatility* (risk) of financial returns, capturing the common phenomenon of volatility clustering.\n",
    "*   **Diagnostics:** Residual analysis is crucial. Even if a model looks good on paper (e.g., low AIC) or performs reasonably on forecasts, checking residuals (plots, Ljung-Box test) reveals if the model assumptions are met and if predictable patterns remain.\n",
    "The failure of the Auto ARIMA residuals to pass the Ljung-Box test is a key teaching point about the limitations of models and the importance of diagnostics.\n",
    "*   **Forecasting Difficulty:** Emphasize that stock price forecasting is inherently challenging due to market efficiency and noise. Simple models often perform similarly to more complex ones for point forecasts.\n",
    "*   **Next Steps (in a real project):** Investigate the Auto ARIMA prediction failure. Explore higher-order models or different structures based on residual diagnostics. Consider non-linear models or Machine Learning approaches (Class 3)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
